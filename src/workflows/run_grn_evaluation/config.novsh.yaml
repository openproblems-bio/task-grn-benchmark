
functionality:
  name: run_grn_evaluation
  namespace: "workflows"
  info:
    label: run_grn_evaluation
    summary: "Evaluates GRNs and provides scores using regression analysis."

  argument_groups:
    - name: Inputs
      arguments:
        - name: --perturbation_data
          __merge__: ../../../api/file_perturbation_h5ad.yaml 
          required: true
          direction: input
          default: resources/grn-benchmark/perturbation_data.h5ad

        - name: --prediction
          type: file 
          required: true
          direction: input
          description: Inferred GRN model

    - name: Outputs
      arguments:
        - name: "--scores"
          type: file
          required: true
          direction: output
          description: A yaml file containing the scores of each of the methods
          default: score_uns.yaml
        - name: "--metric_configs"
          type: file
          required: true
          direction: output
          default: metric_configs.yaml
        - name: "--dataset_uns"
          type: file
          required: true
          direction: output
          default: dataset_uns.yaml
        - name: "--task_info"
          type: file
          required: true
          direction: output
          default: task_info.yaml
    - name: Arguments
      arguments:
        - name: "--metric_ids"
          type: string
          multiple: true
          description: A list of metric ids to run. If not specified, all metric will be run.    
    
  resources:
    - type: nextflow_script
      path: main.nf
      entrypoint: run_wf
  dependencies:
    # - name: common/extract_metadata
    #   repository: openproblemsv2
    - name: metrics/regression_2 
    - name: metrics/regression_1
    # - name: grn_methods/figr
    # - name: grn_methods/scglue
  # repositories:
  #   - name: openproblemsv2
  #     type: github
  #     repo: openproblems-bio/openproblems-v2
  #     tag: main_build
platforms:
  - type: nextflow
    directives:
      label: [ midtime, midmem, lowcpu ]
